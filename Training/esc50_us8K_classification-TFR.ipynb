{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to run classification on ESC50 or UrbanSound8K datasets. Input are spectrogram images transformed from the audio samples.  Look at DataPrep folder for functions to prepare the spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load the images then order them into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from params import *\n",
    "\n",
    "import model_single2 as m #import single-task learning CNN model\n",
    "\n",
    "import utils.pickledModel as pickledModel\n",
    "import utils.spectreader as spectreader\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)  #if want to see full output of big arrays in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_taken(elapsed):\n",
    "    \"\"\"To format time taken in hh:mm:ss. Use with time.monotic()\"\"\"\n",
    "    m, s = divmod(elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%d:%02d:%02d\" % (h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions to save/load numpy arrays to/from file\n",
    "\n",
    "def save_sets(sets,name):\n",
    "    \"\"\"Writes the data array to .npy file. Can be loaded using load_set.\n",
    "    sets: arrays to be saved. can take a list\n",
    "    name: string to name the file. follow same order as in sets \n",
    "    \"\"\" \n",
    "    ind = 0\n",
    "    for x in sets:\n",
    "        np.save(save_path + '/{}.npy'.format(name[ind]), x)\n",
    "        ind += 1\n",
    "\n",
    "def load_set(sets):\n",
    "    \"\"\"Load existing data arrays from .npy files. Use if have preexisting data or when you don't to reshuffle the dataset\"\"\"\n",
    "    return np.load('{}.npy'.format(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FRE_ORIENTATION is \"2D\":\n",
    "    k_height = K_FREQBINS\n",
    "    k_inputChannels = 1\n",
    "elif FRE_ORIENTATION is \"1D\":\n",
    "    k_height = 1\n",
    "    k_inputChannels = K_FREQBINS    \n",
    "else:\n",
    "    raise ValueError(\"please only enter '1D' or '2D'\")\n",
    "\n",
    "\n",
    "# Create list of paramters for serializing so that network can be properly reconstructed, and for documentation purposes\n",
    "parameters={\n",
    "    'k_height' : k_height, \n",
    "    'k_numFrames' : K_NUMFRAMES, \n",
    "    'k_inputChannels' : k_inputChannels, \n",
    "    'K_NUMCONVLAYERS' : m.K_NUMCONVLAYERS, \n",
    "    'L1_CHANNELS' : L1_CHANNELS, \n",
    "    'L2_CHANNELS' : m.L2_CHANNELS, \n",
    "    'FC_SIZE' : FC_SIZE, \n",
    "    'K_ConvRows' : m.K_ConvRows, \n",
    "    'K_ConvCols' : m.K_ConvCols, \n",
    "    'k_ConvStrideRows' : m.k_ConvStrideRows, \n",
    "    'k_ConvStrideCols' : m.k_ConvStrideCols, \n",
    "    'k_poolRows' : m.k_poolRows, \n",
    "    'k_poolStrideRows' : m.k_poolStrideRows, \n",
    "    'k_downsampledHeight' : m.k_downsampledHeight, \n",
    "    'k_downsampledWidth' : m.k_downsampledWidth,\n",
    "    'freqorientation' : FRE_ORIENTATION\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImage(fnames, fre_orientation, nepochs=None) :\n",
    "    \"\"\" Reads data from the prepaired *list* of files in fnames of TFRecords, does some preprocessing \n",
    "    params:\n",
    "    fnames - list of filenames to read data from\n",
    "    nepochs - An integer (optional). Just fed to tf.string_input_producer().  Reads through all data num_epochs times before generating an OutOfRange error. None means read forever.\n",
    "    \"\"\"\n",
    "    label, image = spectreader.getImage(fnames, nepochs)\n",
    "\n",
    "    #same as np.flatten\n",
    "    #image=tf.reshape(image,[k_freqbins*k_numFrames]) \n",
    "    \n",
    "    #no need to flatten - must just be explicit about shape so that shuffle_batch will work\n",
    "    image = tf.reshape(image,[K_FREQBINS,K_NUMFRAMES,NUM_CHANNELS])\n",
    "    if fre_orientation is \"1D\":\n",
    "        image = tf.transpose(image, perm=[0,3,2,1]) #moves freqbins from height to channel dimension\n",
    "\n",
    "    # re-define label as a \"one-hot\" vector \n",
    "    # it will be [0,1] or [1,0] here. \n",
    "    # This approach can easily be extended to more classes.\n",
    "    label=tf.stack(tf.one_hot(label-1, N_LABELS))\n",
    "    print (\"getImage returning\")\n",
    "    return label, image\n",
    "\n",
    "def get_TFR_folds(a_dir, foldnumlist):\n",
    "    \"\"\" Returns a list of files names in a_dir that start with foldX where X is from the foldnumlist\"\"\"\n",
    "    lis = []\n",
    "    for num in foldnumlist : \n",
    "        lis.extend([a_dir + '/' + name for name in os.listdir(a_dir)\n",
    "            if name.startswith(\"fold\"+str(num))])\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "enqueue_threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "try:\n",
    "    if coord.should_stop():\n",
    "        print(\"coord should stop\")\n",
    "\n",
    "    print(\"labelBatch is \" + str(labelBatch))\n",
    "    X_batch, Y_batch = sess.run([imageBatch, labelBatch])\n",
    "    print(\"Y_Batch is \" + str(Y_batch))\n",
    "\n",
    "except (tf.errors.OutOfRangeError) as e:\n",
    "    coord.request_stop(e)\n",
    "\n",
    "finally :\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)    \n",
    "\n",
    "sess.close()\n",
    "    \n",
    "print(\"done\")\n",
    "tf.reset_default_graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now time to train and test the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "foldlist=[1,2,3,4,5]\n",
    "fold=5\n",
    "datanumlist=[x for x in foldlist if x != fold]\n",
    "validatenumlist=[fold]\n",
    "\n",
    "datafnames=get_TFR_folds(\"../DataPrep/stft_png\", datanumlist)\n",
    "target, data = getImage(datafnames, nepochs=EPOCHS)\n",
    "\n",
    "validatefnames=get_TFR_folds(\"../DataPrep/stft_png\", validatenumlist)\n",
    "vtarget, vdata = getImage(validatefnames)\n",
    "\n",
    "NUM_THREADS=2\n",
    "#k_batchsize = batch_size\n",
    "#k_vbatchsize = 2\n",
    "\n",
    "imageBatch, labelBatch = tf.train.shuffle_batch(\n",
    "    [data, target], batch_size=BATCH_SIZE,\n",
    "    num_threads=NUM_THREADS,\n",
    "    allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "    enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "    capacity=1000,  #1000,\n",
    "    min_after_dequeue=500) #500\n",
    "\n",
    "vimageBatch, vlabelBatch = tf.train.batch(\n",
    "    [vdata, vtarget], batch_size=BATCH_SIZE,\n",
    "    num_threads=NUM_THREADS,\n",
    "    allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "    enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "    capacity=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "filewriter_path = save_path + \"/filewriter/\"\n",
    "checkpoint_path = save_path + \"/checkpoint/\"\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path): os.mkdir(checkpoint_path)\n",
    "\n",
    "#********************************************************************\n",
    "\n",
    "# tf Graph input placeholders\n",
    "if FRE_ORIENTATION is \"2D\":\n",
    "    x = tf.placeholder(tf.float32, [BATCH_SIZE, K_FREQBINS, K_NUMFRAMES, NUM_CHANNELS])\n",
    "elif FRE_ORIENTATION is \"1D\":\n",
    "    x = tf.placeholder(tf.float32, [BATCH_SIZE, NUM_CHANNELS, K_NUMFRAMES, K_FREQBINS])\n",
    "\n",
    "y = tf.placeholder(tf.int32, [None, N_LABELS])\n",
    "keep_prob = tf.placeholder(tf.float32, (), name=\"keepProb\") #dropout (keep probability)\n",
    "\n",
    "# Construct model\n",
    "pred = m.conv_net(x, m.weights, m.biases, keep_prob)\n",
    "\n",
    "#L2 regularization\n",
    "lossL2 = tf.add_n([tf.nn.l2_loss(val) for name,val in m.weights.items()]) * beta #L2 reg on all weight layers\n",
    "lossL2_onlyfull = tf.add_n([tf.nn.l2_loss(m.weights['wd1']),tf.nn.l2_loss(m.weights['wout'])]) * beta #L2 reg on dense layers\n",
    "\n",
    "# Op for calculating the loss\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    if l2reg:\n",
    "        if l2regfull:\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y) + lossL2_onlyfull)\n",
    "        else:\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y) + lossL2)\n",
    "    else:\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "# Train op\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(epsilon=epsilon).minimize(loss)\n",
    "\n",
    "# Add the loss to summary\n",
    "tf.summary.scalar('cross_entropy', loss)\n",
    "\n",
    "# Predictions\n",
    "prob = tf.nn.softmax(pred)\n",
    "\n",
    "# Evaluation op: Accuracy of the model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(prob, 1), tf.argmax(y, 1))\n",
    "    accuracy = 100*tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Add the accuracy to the summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-25 14:05:23.419506 Open Tensorboard at --logdir ../Results/filewriter/\n",
      "getImage ['../DataPrep/stft_png/fold2-00003-of-00004', '../DataPrep/stft_png/fold2-00000-of-00004', '../DataPrep/stft_png/fold2-00001-of-00004', '../DataPrep/stft_png/fold2-00002-of-00004', '../DataPrep/stft_png/fold3-00000-of-00004', '../DataPrep/stft_png/fold3-00002-of-00004', '../DataPrep/stft_png/fold3-00001-of-00004', '../DataPrep/stft_png/fold3-00003-of-00004', '../DataPrep/stft_png/fold4-00002-of-00004', '../DataPrep/stft_png/fold4-00003-of-00004', '../DataPrep/stft_png/fold4-00001-of-00004', '../DataPrep/stft_png/fold4-00000-of-00004', '../DataPrep/stft_png/fold5-00001-of-00004', '../DataPrep/stft_png/fold5-00002-of-00004', '../DataPrep/stft_png/fold5-00000-of-00004', '../DataPrep/stft_png/fold5-00003-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "getImage ['../DataPrep/stft_png/fold1-00002-of-00004', '../DataPrep/stft_png/fold1-00003-of-00004', '../DataPrep/stft_png/fold1-00000-of-00004', '../DataPrep/stft_png/fold1-00001-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_1:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "*** Initializing fold #1 as test set ***\n",
      "2017-07-25 14:05:24.145502 Start training...\n",
      "2017-07-25 14:05:24.145728 Epoch number: 1\n",
      "2017-07-25 14:05:33.633914 Test Accuracy = 7.5000\n",
      "2017-07-25 14:05:33.635888 Epoch number: 2\n",
      "2017-07-25 14:05:41.365720 Test Accuracy = 8.2500\n",
      "2017-07-25 14:05:41.366124 Epoch number: 3\n",
      "2017-07-25 14:05:49.121585 Test Accuracy = 15.0000\n",
      "2017-07-25 14:05:49.122949 Epoch number: 4\n",
      "2017-07-25 14:05:56.915686 Test Accuracy = 18.0000\n",
      "2017-07-25 14:05:56.915879 Epoch number: 5\n",
      "2017-07-25 14:06:04.583178 Test Accuracy = 19.5000\n",
      "2017-07-25 14:06:04.584047 Epoch number: 6\n",
      "40.45516801999838\n",
      "--- Training time taken: 0:00:40 ---\n",
      "------------------------\n",
      "[19.500000524520875]\n",
      "[5]\n",
      "getImage ['../DataPrep/stft_png/fold1-00002-of-00004', '../DataPrep/stft_png/fold1-00003-of-00004', '../DataPrep/stft_png/fold1-00000-of-00004', '../DataPrep/stft_png/fold1-00001-of-00004', '../DataPrep/stft_png/fold3-00000-of-00004', '../DataPrep/stft_png/fold3-00002-of-00004', '../DataPrep/stft_png/fold3-00001-of-00004', '../DataPrep/stft_png/fold3-00003-of-00004', '../DataPrep/stft_png/fold4-00002-of-00004', '../DataPrep/stft_png/fold4-00003-of-00004', '../DataPrep/stft_png/fold4-00001-of-00004', '../DataPrep/stft_png/fold4-00000-of-00004', '../DataPrep/stft_png/fold5-00001-of-00004', '../DataPrep/stft_png/fold5-00002-of-00004', '../DataPrep/stft_png/fold5-00000-of-00004', '../DataPrep/stft_png/fold5-00003-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_2:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "getImage ['../DataPrep/stft_png/fold2-00003-of-00004', '../DataPrep/stft_png/fold2-00000-of-00004', '../DataPrep/stft_png/fold2-00001-of-00004', '../DataPrep/stft_png/fold2-00002-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_3:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "*** Initializing fold #2 as test set ***\n",
      "2017-07-25 14:06:04.919861 Start training...\n",
      "2017-07-25 14:06:04.920262 Epoch number: 1\n",
      "2017-07-25 14:06:14.848801 Test Accuracy = 7.5000\n",
      "2017-07-25 14:06:14.850662 Epoch number: 2\n",
      "2017-07-25 14:06:22.907351 Test Accuracy = 7.0000\n",
      "2017-07-25 14:06:22.907579 Epoch number: 3\n",
      "2017-07-25 14:06:30.838372 Test Accuracy = 13.0000\n",
      "2017-07-25 14:06:30.838569 Epoch number: 4\n",
      "2017-07-25 14:06:38.764012 Test Accuracy = 15.2500\n",
      "2017-07-25 14:06:38.764458 Epoch number: 5\n",
      "2017-07-25 14:06:46.484967 Test Accuracy = 21.0000\n",
      "2017-07-25 14:06:46.486050 Epoch number: 6\n",
      "41.63090614700013\n",
      "--- Training time taken: 0:00:41 ---\n",
      "------------------------\n",
      "[19.500000524520875, 21.000000572204591]\n",
      "[5, 5]\n",
      "getImage ['../DataPrep/stft_png/fold1-00002-of-00004', '../DataPrep/stft_png/fold1-00003-of-00004', '../DataPrep/stft_png/fold1-00000-of-00004', '../DataPrep/stft_png/fold1-00001-of-00004', '../DataPrep/stft_png/fold2-00003-of-00004', '../DataPrep/stft_png/fold2-00000-of-00004', '../DataPrep/stft_png/fold2-00001-of-00004', '../DataPrep/stft_png/fold2-00002-of-00004', '../DataPrep/stft_png/fold4-00002-of-00004', '../DataPrep/stft_png/fold4-00003-of-00004', '../DataPrep/stft_png/fold4-00001-of-00004', '../DataPrep/stft_png/fold4-00000-of-00004', '../DataPrep/stft_png/fold5-00001-of-00004', '../DataPrep/stft_png/fold5-00002-of-00004', '../DataPrep/stft_png/fold5-00000-of-00004', '../DataPrep/stft_png/fold5-00003-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_4:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "getImage ['../DataPrep/stft_png/fold3-00000-of-00004', '../DataPrep/stft_png/fold3-00002-of-00004', '../DataPrep/stft_png/fold3-00001-of-00004', '../DataPrep/stft_png/fold3-00003-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_5:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "*** Initializing fold #3 as test set ***\n",
      "2017-07-25 14:06:46.881848 Start training...\n",
      "2017-07-25 14:06:46.881981 Epoch number: 1\n",
      "2017-07-25 14:06:57.762723 Test Accuracy = 5.0000\n",
      "2017-07-25 14:06:57.763112 Epoch number: 2\n",
      "2017-07-25 14:07:05.676025 Test Accuracy = 10.7500\n",
      "2017-07-25 14:07:05.676221 Epoch number: 3\n",
      "2017-07-25 14:07:13.571898 Test Accuracy = 11.2500\n",
      "2017-07-25 14:07:13.572129 Epoch number: 4\n",
      "2017-07-25 14:07:21.426770 Test Accuracy = 14.2500\n",
      "2017-07-25 14:07:21.428966 Epoch number: 5\n",
      "2017-07-25 14:07:29.176540 Test Accuracy = 16.0000\n",
      "2017-07-25 14:07:29.177464 Epoch number: 6\n",
      "42.361025919000895\n",
      "--- Training time taken: 0:00:42 ---\n",
      "------------------------\n",
      "[19.500000524520875, 21.000000572204591, 16.000000286102296]\n",
      "[5, 5, 5]\n",
      "getImage ['../DataPrep/stft_png/fold1-00002-of-00004', '../DataPrep/stft_png/fold1-00003-of-00004', '../DataPrep/stft_png/fold1-00000-of-00004', '../DataPrep/stft_png/fold1-00001-of-00004', '../DataPrep/stft_png/fold2-00003-of-00004', '../DataPrep/stft_png/fold2-00000-of-00004', '../DataPrep/stft_png/fold2-00001-of-00004', '../DataPrep/stft_png/fold2-00002-of-00004', '../DataPrep/stft_png/fold3-00000-of-00004', '../DataPrep/stft_png/fold3-00002-of-00004', '../DataPrep/stft_png/fold3-00001-of-00004', '../DataPrep/stft_png/fold3-00003-of-00004', '../DataPrep/stft_png/fold5-00001-of-00004', '../DataPrep/stft_png/fold5-00002-of-00004', '../DataPrep/stft_png/fold5-00000-of-00004', '../DataPrep/stft_png/fold5-00003-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_6:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "getImage ['../DataPrep/stft_png/fold4-00002-of-00004', '../DataPrep/stft_png/fold4-00003-of-00004', '../DataPrep/stft_png/fold4-00001-of-00004', '../DataPrep/stft_png/fold4-00000-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_7:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "*** Initializing fold #4 as test set ***\n",
      "2017-07-25 14:07:29.607135 Start training...\n",
      "2017-07-25 14:07:29.607267 Epoch number: 1\n",
      "2017-07-25 14:07:41.189489 Test Accuracy = 4.2500\n",
      "2017-07-25 14:07:41.189681 Epoch number: 2\n",
      "2017-07-25 14:07:49.072812 Test Accuracy = 8.7500\n",
      "2017-07-25 14:07:49.076928 Epoch number: 3\n",
      "2017-07-25 14:07:56.947530 Test Accuracy = 10.2500\n",
      "2017-07-25 14:07:56.948561 Epoch number: 4\n",
      "2017-07-25 14:08:04.809081 Test Accuracy = 12.5000\n",
      "2017-07-25 14:08:04.809454 Epoch number: 5\n",
      "2017-07-25 14:08:12.567191 Test Accuracy = 15.2500\n",
      "2017-07-25 14:08:12.568427 Epoch number: 6\n",
      "43.09047448199999\n",
      "--- Training time taken: 0:00:43 ---\n",
      "------------------------\n",
      "[19.500000524520875, 21.000000572204591, 16.000000286102296, 15.250000190734863]\n",
      "[5, 5, 5, 5]\n",
      "getImage ['../DataPrep/stft_png/fold1-00002-of-00004', '../DataPrep/stft_png/fold1-00003-of-00004', '../DataPrep/stft_png/fold1-00000-of-00004', '../DataPrep/stft_png/fold1-00001-of-00004', '../DataPrep/stft_png/fold2-00003-of-00004', '../DataPrep/stft_png/fold2-00000-of-00004', '../DataPrep/stft_png/fold2-00001-of-00004', '../DataPrep/stft_png/fold2-00002-of-00004', '../DataPrep/stft_png/fold3-00000-of-00004', '../DataPrep/stft_png/fold3-00002-of-00004', '../DataPrep/stft_png/fold3-00001-of-00004', '../DataPrep/stft_png/fold3-00003-of-00004', '../DataPrep/stft_png/fold4-00002-of-00004', '../DataPrep/stft_png/fold4-00003-of-00004', '../DataPrep/stft_png/fold4-00001-of-00004', '../DataPrep/stft_png/fold4-00000-of-00004']\n",
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_8:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "getImage ['../DataPrep/stft_png/fold5-00001-of-00004', '../DataPrep/stft_png/fold5-00002-of-00004', '../DataPrep/stft_png/fold5-00000-of-00004', '../DataPrep/stft_png/fold5-00003-of-00004']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecordReader produced Tensor(\"ReaderNumRecordsProducedV2_9:0\", shape=(), dtype=int64) records\n",
      "getImage returning\n",
      "*** Initializing fold #5 as test set ***\n",
      "2017-07-25 14:08:13.144403 Start training...\n",
      "2017-07-25 14:08:13.144536 Epoch number: 1\n",
      "2017-07-25 14:08:25.288163 Test Accuracy = 5.5000\n",
      "2017-07-25 14:08:25.288854 Epoch number: 2\n",
      "2017-07-25 14:08:33.271746 Test Accuracy = 7.0000\n",
      "2017-07-25 14:08:33.271954 Epoch number: 3\n",
      "2017-07-25 14:08:41.129375 Test Accuracy = 9.5000\n",
      "2017-07-25 14:08:41.131456 Epoch number: 4\n",
      "2017-07-25 14:08:49.084533 Test Accuracy = 9.7500\n",
      "2017-07-25 14:08:49.084848 Epoch number: 5\n",
      "2017-07-25 14:08:56.858710 Test Accuracy = 14.2500\n",
      "2017-07-25 14:08:56.859165 Epoch number: 6\n",
      "43.97479528400072\n",
      "--- Training time taken: 0:00:43 ---\n",
      "------------------------\n",
      "[19.500000524520875, 21.000000572204591, 16.000000286102296, 15.250000190734863, 14.250000476837158]\n",
      "[5, 5, 5, 5, 5]\n",
      "*** All runs completed ***\n",
      "Total time taken: 0:03:33\n"
     ]
    }
   ],
   "source": [
    "NUM_THREADS = 4\n",
    "foldlist = [1,2,3,4,5]\n",
    "max_acc = []\n",
    "max_epochs = []\n",
    "\n",
    "start_time_long = time.monotonic()\n",
    "text_file = open(save_path + \"/stft-double_v2.txt\", \"w\") #save training data\n",
    "print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(), filewriter_path))\n",
    "\n",
    "for fold in foldlist:\n",
    "    \n",
    "    test_acc_list = []\n",
    "    \n",
    "    datanumlist=[x for x in foldlist if x != fold]\n",
    "    validatenumlist=[fold]\n",
    "\n",
    "    datafnames=get_TFR_folds(INDIR, datanumlist)\n",
    "    target, data = getImage(datafnames, FRE_ORIENTATION, nepochs=EPOCHS)\n",
    "\n",
    "    validatefnames=get_TFR_folds(INDIR, validatenumlist)\n",
    "    vtarget, vdata = getImage(validatefnames, FRE_ORIENTATION)\n",
    "\n",
    "    imageBatch, labelBatch = tf.train.shuffle_batch(\n",
    "        [data, target], batch_size=BATCH_SIZE,\n",
    "        num_threads=NUM_THREADS,\n",
    "        allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "        enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "        capacity=1000,  #1000,\n",
    "        min_after_dequeue=500) #500\n",
    "\n",
    "    vimageBatch, vlabelBatch = tf.train.batch(\n",
    "        [vdata, vtarget], batch_size=BATCH_SIZE,\n",
    "        num_threads=NUM_THREADS,\n",
    "        allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "        enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "        capacity=1000)\n",
    "\n",
    "\n",
    "    text_file.write('*** Initializing fold #%u as test set ***\\n' % fold)\n",
    "    print('*** Initializing fold #%u as test set ***' % fold)\n",
    "\n",
    "    # Initialize the FileWriter\n",
    "    writer = tf.summary.FileWriter(filewriter_path + str(fold))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Initialize all variables        \n",
    "        sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "        # Add the model graph to TensorBoard\n",
    "        writer.add_graph(sess.graph)\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        enqueue_threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "        print(\"{} Start training...\".format(datetime.now()))\n",
    "        start_time = time.monotonic()\n",
    "\n",
    "        try:\n",
    "            if coord.should_stop():\n",
    "                print(\"coord should stop\")\n",
    "\n",
    "            e = 1\n",
    "            step = 1\n",
    "            print(\"{} Epoch number: {}\".format(datetime.now(), e))\n",
    "\n",
    "            while True:  # for each minibatch until data runs out after specified number of epochs\n",
    "                if coord.should_stop():\n",
    "                    print(\"data feed done, quitting\")\n",
    "                    break\n",
    "\n",
    "                #create training mini-batch here\n",
    "                batch_data, batch_labels = sess.run([imageBatch, labelBatch])\n",
    "                #train and backprop\n",
    "                sess.run(optimizer, feed_dict= {x:batch_data, y:batch_labels, keep_prob:dropout})\n",
    "\n",
    "                #print(\"step = \" + str(step))\n",
    "\n",
    "                #run merged_summary to display progress on Tensorboard\n",
    "                #print(\"run summary\")\n",
    "                if (step % display_step == 0):               \n",
    "                    s = sess.run(merged_summary, feed_dict={x: batch_data, y: batch_labels, keep_prob: 1.})\n",
    "                    ##writer.add_summary(s, e*train_batches_per_epoch + step) \n",
    "                    writer.add_summary(s, step)\n",
    "\n",
    "                if (step % testNSteps == 0):\n",
    "                    test_acc = 0.\n",
    "                    test_count = 0\n",
    "                    #print(\"now test for \" + str(test_batches_per_epoch) + \" test steps\")\n",
    "                    for j in range(test_batches_per_epoch):\n",
    "                        #print(\"test step = \" + str(j))\n",
    "                        try:\n",
    "                            #prepare test mini-batch\n",
    "                            test_batch, label_batch = sess.run([vimageBatch, vlabelBatch])\n",
    "\n",
    "                            acc = sess.run(accuracy, feed_dict={x: test_batch, y: label_batch, keep_prob: 1.})\n",
    "                            test_acc += acc*BATCH_SIZE\n",
    "                            test_count += 1*BATCH_SIZE\n",
    "                        except (Exception) as ex: #triggered if we run out of validation data to feed queue\n",
    "                            print(ex)\n",
    "\n",
    "                    #calculate total test accuracy\n",
    "                    test_acc /= test_count \n",
    "                    print(\"{} Test Accuracy = {:.4f}\".format(datetime.now(),test_acc))\n",
    "                    text_file.write(\"{} Test Accuracy = {:.4f}\\n\".format(datetime.now(),test_acc))\n",
    "                    test_acc_list.append(test_acc)\n",
    "\n",
    "                if (step % train_batches_per_epoch == 0):\n",
    "                    e += 1\n",
    "                    print(\"{} Epoch number: {}\".format(datetime.now(), e))\n",
    "                     #save checkpoint of the model\n",
    "                    if (e % checkpoint_epoch == 0):  \n",
    "                        checkpoint_name = os.path.join(checkpoint_path, dataset_name+'model_fold'+str(fold)+'_epoch'+str(e)+'.ckpt')\n",
    "                        saver.save(sess, checkpoint_name) \n",
    "                        print(\"{} Model checkpoint saved at {}\".format(datetime.now(), checkpoint_name))\n",
    "\n",
    "                step += 1\n",
    "\n",
    "        except (tf.errors.OutOfRangeError) as ex:\n",
    "            coord.request_stop(ex)\n",
    "\n",
    "        finally :\n",
    "            coord.request_stop()\n",
    "            coord.join(enqueue_threads)                                      \n",
    "        \n",
    "        # find the max test score and the epoch it belongs to        \n",
    "        max_acc.append(max(test_acc_list))\n",
    "        max_epoch = test_acc_list.index(max(test_acc_list))+1\n",
    "        max_epochs.append(max_epoch) \n",
    "\n",
    "        elapsed_time = time.monotonic() - start_time\n",
    "        print(elapsed_time)\n",
    "        text_file.write(\"--- Training time taken: {} ---\\n\".format(time_taken(elapsed_time)))\n",
    "        print(\"--- Training time taken:\",time_taken(elapsed_time),\"---\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "        # return the max accuracies of each fold and their respective epochs\n",
    "        print(max_acc)\n",
    "        print(max_epochs)\n",
    "\n",
    "    sess.close()\n",
    "    #tf.reset_default_graph() \n",
    "\n",
    "writer.close()\n",
    "elapsed_time_long = time.monotonic() - start_time_long\n",
    "print(\"*** All runs completed ***\")\n",
    "text_file.write(\"Total time taken:\")\n",
    "text_file.write(time_taken(elapsed_time_long))\n",
    "print(\"Total time taken:\",time_taken(elapsed_time_long))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {a:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "a = tf.Print(m.weights['wc1'],[m.weights['wc1']])\n",
    "#print(a)\n",
    "#         print(m.weights)\n",
    "#         print(m.biases)\n",
    "#     trainable = [m.weights,m.biases]\n",
    "#     state={}\n",
    "#     for v in trainable[0] :\n",
    "#         state[v.name] = sess.run(v)\n",
    "#     print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_graph_def = tf.train.export_meta_graph(filename=OUTDIR + '/my-model.meta')\n",
    "pickledModel.saveState(sess, trainable, parameters, OUTDIR + '/state.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foldlist=[1,2,3,4,5]\n",
    "fold=4\n",
    "datanumlist=[x for x in foldlist if x != fold]\n",
    "validatenumlist=[fold]\n",
    "\n",
    "datafnames=get_TFR_folds(\"../DataPrep/stft_png\", datanumlist)\n",
    "target, data = getImage(datafnames, nepochs=EPOCHS)\n",
    "\n",
    "validatefnames=get_TFR_folds(\"../DataPrep/stft_png\", validatenumlist)\n",
    "vtarget, vdata = getImage(validatefnames)\n",
    "\n",
    "NUM_THREADS=2\n",
    "#k_batchsize = batch_size\n",
    "#k_vbatchsize = 2\n",
    "\n",
    "imageBatch, labelBatch = tf.train.shuffle_batch(\n",
    "    [data, target], batch_size=BATCH_SIZE,\n",
    "    num_threads=NUM_THREADS,\n",
    "    allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "    enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "    capacity=1000,  #1000,\n",
    "    min_after_dequeue=500) #500\n",
    "\n",
    "vimageBatch, vlabelBatch = tf.train.batch(\n",
    "    [vdata, vtarget], batch_size=BATCH_SIZE,\n",
    "    num_threads=NUM_THREADS,\n",
    "    allow_smaller_final_batch=True, #want to finish an eposh even if datasize doesn't divide by batchsize\n",
    "    enqueue_many=False, #IMPORTANT to get right, default=False - \n",
    "    capacity=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_acc = []\n",
    "max_epochs = []\n",
    "test_acc_list = []\n",
    "\n",
    "start_time_long = time.monotonic()\n",
    "text_file = open(save_path + \"/stft-double_v2.txt\", \"w\") #save training data\n",
    "print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(), filewriter_path))\n",
    "\n",
    "text_file.write('*** Initializing fold #%u as test set ***\\n' % fold)\n",
    "print('*** Initializing fold #%u as test set ***' % fold)\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path + str(fold))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initialize all variables        \n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    try:\n",
    "        if coord.should_stop():\n",
    "            print(\"coord should stop\")\n",
    "\n",
    "        e = 1\n",
    "        step = 1\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), e))\n",
    "\n",
    "        while True:  # for each minibatch until data runs out after specified number of epochs\n",
    "            if coord.should_stop():\n",
    "                print(\"data feed done, quitting\")\n",
    "                break\n",
    "\n",
    "            #create training mini-batch here\n",
    "            batch_data, batch_labels = sess.run([imageBatch, labelBatch])\n",
    "            #train and backprop\n",
    "            sess.run(optimizer, feed_dict= {x:batch_data, y:batch_labels, keep_prob:dropout})\n",
    "            \n",
    "            #print(\"step = \" + str(step))\n",
    "                \n",
    "            #run merged_summary to display progress on Tensorboard\n",
    "            #print(\"run summary\")\n",
    "            if (step % display_step == 0):               \n",
    "                s = sess.run(merged_summary, feed_dict={x: batch_data, y: batch_labels, keep_prob: 1.})\n",
    "                ##writer.add_summary(s, e*train_batches_per_epoch + step) \n",
    "                writer.add_summary(s, step)\n",
    "\n",
    "            if (step % testNSteps == 0):\n",
    "                test_acc = 0.\n",
    "                test_count = 0\n",
    "                #print(\"now test for \" + str(test_batches_per_epoch) + \" test steps\")\n",
    "                for j in range(test_batches_per_epoch):\n",
    "                    #print(\"test step = \" + str(j))\n",
    "                    try:\n",
    "                        #prepare test mini-batch\n",
    "                        test_batch, label_batch = sess.run([vimageBatch, vlabelBatch])\n",
    "\n",
    "                        acc = sess.run(accuracy, feed_dict={x: test_batch, y: label_batch, keep_prob: 1.})\n",
    "                        test_acc += acc*BATCH_SIZE\n",
    "                        test_count += 1*BATCH_SIZE\n",
    "                    except (Exception) as ex: #triggered if we run out of validation data to feed queue\n",
    "                        print(ex)\n",
    "\n",
    "                #calculate total test accuracy\n",
    "                test_acc /= test_count \n",
    "                print(\"{} Test Accuracy = {:.4f}\".format(datetime.now(),test_acc))\n",
    "                text_file.write(\"{} Test Accuracy = {:.4f}\\n\".format(datetime.now(),test_acc))\n",
    "                test_acc_list.append(test_acc)\n",
    "            \n",
    "            if (step % train_batches_per_epoch == 0):\n",
    "                e += 1\n",
    "                print(\"{} Epoch number: {}\".format(datetime.now(), e))\n",
    "                 #save checkpoint of the model\n",
    "                if (e % checkpoint_epoch == 0):  \n",
    "                    checkpoint_name = os.path.join(checkpoint_path, dataset_name+'model_fold'+str(fold)+'_epoch'+str(e)+'.ckpt')\n",
    "                    saver.save(sess, checkpoint_name) \n",
    "                    print(\"{} Model checkpoint saved at {}\".format(datetime.now(), checkpoint_name))\n",
    "\n",
    "            step += 1\n",
    "                                              \n",
    "    except (tf.errors.OutOfRangeError) as ex:\n",
    "        coord.request_stop(ex)\n",
    "\n",
    "    finally :\n",
    "        coord.request_stop()\n",
    "        coord.join(enqueue_threads)                                      \n",
    "                                    \n",
    "# find the max test score and the epoch it belongs to        \n",
    "max_acc.append(max(test_acc_list))\n",
    "max_epoch = test_acc_list.index(max(test_acc_list))+1\n",
    "max_epochs.append(max_epoch) \n",
    "\n",
    "elapsed_time = time.monotonic() - start_time\n",
    "print(elapsed_time)\n",
    "text_file.write(\"--- Training time taken: {} ---\\n\".format(time_taken(elapsed_time)))\n",
    "print(\"--- Training time taken:\",time_taken(elapsed_time),\"---\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "# return the max accuracies of each fold and their respective epochs\n",
    "print(max_acc)\n",
    "print(max_epochs)\n",
    "\n",
    "\n",
    "writer.close()\n",
    "elapsed_time_long = time.monotonic() - start_time_long\n",
    "print(\"*** Fold completed ***\")\n",
    "text_file.write(\"Total time taken:\")\n",
    "text_file.write(time_taken(elapsed_time_long))\n",
    "print(\"Total time taken:\",time_taken(elapsed_time_long))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
